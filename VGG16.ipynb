{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import os\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiabeticRetinopathyDataset(Dataset):\n",
    "    def __init__(self, base_dir, transform=None):\n",
    "        self.base_dir = base_dir\n",
    "        self.transform = transform\n",
    "        self.data = []\n",
    "        categories = ['No_DR', 'Mild', 'Moderate', 'Severe', 'Proliferate_DR']\n",
    "\n",
    "        for idx, category in enumerate(categories):\n",
    "            path = os.path.join(base_dir, category)\n",
    "            images = os.listdir(path)[:1000]  # Take only 1000 images per category\n",
    "            for image in images:\n",
    "                self.data.append((os.path.join(path, image), idx))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.data[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Assuming 'base_dir' is your dataset directory path\n",
    "base_dir = 'data/gaussian_filtered_images/gaussian_filtered_images/'  # Update this path\n",
    "dataset = DiabeticRetinopathyDataset(base_dir=base_dir, transform=transform)\n",
    "\n",
    "# Splitting the dataset into train and validation\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /home/pavan/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de3dc02ec6fe4e829753172665b05654",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/528M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "# Load the pre-trained VGG16 model\n",
    "model = models.vgg16(pretrained=True)\n",
    "\n",
    "# Freeze the parameters of the feature extractor\n",
    "for param in model.features.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Modify the classifier to fit your dataset (assuming 5 classes here)\n",
    "num_features = model.classifier[6].in_features  # Get the input features of the last layer\n",
    "features = list(model.classifier.children())[:-1]  # Remove the last layer\n",
    "features.extend([nn.Linear(num_features, 5)])  # Append a new layer with 5 outputs\n",
    "model.classifier = nn.Sequential(*features)  # Replace the classifier with the updated one\n",
    "\n",
    "# Move the model to the appropriate device (GPU or CPU)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# Define the loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define the optimizer (only update the parameters of the classifier)\n",
    "optimizer = torch.optim.Adam(model.classifier.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 1.3091132822963927, Validation Loss: 1.3728201852904425, Validation Accuracy: 65.73426573426573%\n",
      "Epoch 2, Train Loss: 1.0425565822256937, Validation Loss: 1.066296613878674, Validation Accuracy: 64.16083916083916%\n",
      "Epoch 3, Train Loss: 1.0500584178500705, Validation Loss: 0.888153549697664, Validation Accuracy: 68.35664335664336%\n",
      "Epoch 4, Train Loss: 1.005998203323947, Validation Loss: 0.9868426654073927, Validation Accuracy: 66.43356643356644%\n",
      "Epoch 5, Train Loss: 1.046581512524022, Validation Loss: 0.9414576888084412, Validation Accuracy: 68.88111888111888%\n",
      "Epoch 6, Train Loss: 0.9826627195709281, Validation Loss: 0.8358578003115125, Validation Accuracy: 69.93006993006993%\n",
      "Epoch 7, Train Loss: 0.9021041898263825, Validation Loss: 1.0065177513493433, Validation Accuracy: 69.58041958041959%\n",
      "Epoch 8, Train Loss: 0.8250648917423354, Validation Loss: 1.0562109053134918, Validation Accuracy: 69.4055944055944%\n",
      "Epoch 9, Train Loss: 0.8899451171358427, Validation Loss: 1.1785103744930692, Validation Accuracy: 69.23076923076923%\n",
      "Epoch 10, Train Loss: 0.9155445210635662, Validation Loss: 0.9685034255186716, Validation Accuracy: 71.32867132867133%\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    print(f'Epoch {epoch+1}, Train Loss: {running_loss / len(train_loader)}, Validation Loss: {val_loss / len(val_loader)}, Validation Accuracy: {100 * correct / total}%')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
